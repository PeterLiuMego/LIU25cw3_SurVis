define({ entries : {
    "Beck2016Visual": {
        "abstract": "Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.",
        "author": "Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel",
        "doi": "10.1109/TVCG.2015.2467757",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser",
        "number": "01",
        "publisher": "IEEE",
        "series": "TVCG",
        "title": "Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}",
        "type": "article",
        "url": "http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf",
        "volume": "22",
        "year": "2016"
    },
    "Li2023": {
        "abstract": "Shadows often occur when we capture the document with casual equipment, which influences the visual quality and readability of the digital copies. Different from the algorithms for natural shadow removal, the algorithms in document shadow removal need to preserve the details of fonts and figures in high-resolution input. Previous works ignore this problem and remove the shadows via approximate attention and small datasets, which might not work in real-world situations. We handle high-resolution document shadow removal directly via a larger-scale real-world dataset and a carefully-designed frequency-aware network. As for the dataset, we acquire over 7k couples of high-resolution (2462 \u00d7 3699) images of real-world documents pairs with various samples under different lighting circumstances, which is 10 times larger than existing datasets. As for the design of the network, we decouple the high-resolution images in the frequency domain, where the low-frequency details and high-frequency boundaries can be effectively learned via the carefully designed network structure. Powered by our network and dataset, the proposed method shows a clearly better performance than previous methods in terms of visual quality and numerical results. The code, models, and dataset are available at https://github.com/CXH-Research/DocShadow-SD7K.",
        "author": "Li, Z. and Chen, X. and Pun, C.-M. and Cun, X.",
        "booktitle": "2023 IEEE/CVF International Conference on Computer Vision (ICCV)",
        "doi": "10.1109/ICCV51070.2023.01144",
        "issn": "2380-7504",
        "keywords": "type:Visualization, Computer vision, Laplace equations, Image resolution, Codes, Frequency-domain analysis, Lighting",
        "pages": "12415-12424",
        "series": "2023 IEEE/CVF International Conference on Computer Vision (ICCV)",
        "title": "High-Resolution Document Shadow Removal via A Large-Scale Real-World Dataset and A Frequency-Aware Shadow Erasing Net",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/ICCV51070.2023.01144",
        "year": "2023"
    },
    "Lin2020": {
        "abstract": "Removing shadows in document images enhances both the visual quality and readability of digital copies of documents. Most existing shadow removal algorithms for document images use hand-crafted heuristics and are often not robust to documents with different characteristics. This paper proposes the Background Estimation Document Shadow Removal Network (BEDSR-Net), the first deep network specifically designed for document image shadow removal. For taking advantage of specific properties of document images, a background estimation module is designed for extracting the global background color of the document. During the process of estimating the background color, the module also learns information about the spatial distribution of background and non-background pixels. We encode such information into an attention map. With the estimated global background color and attention map, the shadow removal network can better recover the shadow-free image. We also show that the model trained on synthetic images remains effective for real photos, and provide a large set of synthetic shadow images of documents along with their corresponding shadow-free images and shadow masks. Extensive quantitative and qualitative experiments on several benchmarks show that the BEDSR-Net outperforms existing methods in enhancing both the visual quality and readability of document images.",
        "author": "Lin, Y.-H. and Chen, W.-C. and Chuang, Y.-Y.",
        "booktitle": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "doi": "10.1109/CVPR42600.2020.01292",
        "issn": "2575-7075",
        "keywords": "type:Image color analysis,Training,Estimation,Cameras,Nickel,Lighting,Visualization",
        "pages": "12902-12911",
        "series": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "title": "BEDSR-Net: A Deep Shadow Removal Network From a Single Document Image",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/CVPR42600.2020.01292",
        "year": "2020"
    },
    "Liu2023": {
        "abstract": "This paper proposes a simple yet effective method to re-move shadows from text document images. It mainly includes several parts. Firstly, we propose a text elimination-based background extraction strategy to estimate shadow map. It indicates the shadow regions accurately and helps to predict global background. Secondly, a binarization-based text ex-traction algorithm is designed to obtain texts from document image. By fusing texts and global background, a preparatory shadow-free image can be obtained. Thirdly, we propose an adaptive text contrast enhancement strategy to generate shadow-free results with comfortable visual perception across shadow and non-shadow regions. Quantitative and visual results performed on open datasets indicate that the proposed method can generate clear shadow-free images from text document images. Our code will be publicly available soon.",
        "author": "Liu, W. and Wang, B. and Zheng, J. and Wang, W.",
        "booktitle": "ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "doi": "10.1109/ICASSP49357.2023.10096115",
        "issn": "2379-190X",
        "keywords": "type:shadow removal, text document images, shadow map, contrast enhancement",
        "pages": "1-5",
        "series": "ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "title": "Shadow Removal of Text Document Images Using Background Estimation and Adaptive Text Enhancement",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/ICASSP49357.2023.10096115",
        "year": "2023"
    },
    "Liu2025": {
        "abstract": "This study proposes a novel and highly efficient approach for the comprehensive removal of shadows from digitized images that is applicable to a broad spectrum of image types, from document scans to natural scenes. The proposed method introduces an RGB water-filling algorithm specifically designed to address soft shadows, optimized with matrix operations and a streamlined processing workflow that substantially enhance the computational efficiency over existing methods. This improved efficiency facilitates real-time applications such as vision systems in automated guided vehicles, which often contend with shadow interference in natural environments. In addition to soft shadows, the proposed method addresses hard shadows, which can severely degrade the image quality and leave residual shadow boundaries that are difficult to eliminate using conventional techniques. To overcome this, the proposed method combines the RGB water-filling algorithm with the penumbra removal technique that not only removes shadow boundaries but also reconstructs the underlying image background. A comparative analysis demonstrates that the proposed method significantly reduces the root mean squared error (RMSE) by 70% and the processing time by 99%, while achieving the highest peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM), outperforming previous approaches for both soft and hard shadow removal.",
        "author": "Liu, Y.-C. and Chuang, C.-T.",
        "doi": "10.1109/ACCESS.2025.3555302",
        "issn": "2169-3536",
        "journal": "IEEE Access",
        "keywords": "type:Image processing, shadow, shadow removal, water-filling algorithm",
        "pages": "57847-57857",
        "title": "Combining the Improved RGB Water-Filling Algorithm With Penumbra Removal Technique for Shadow Removal From Digitized Images",
        "type": "Article",
        "url": "https://doi.org/10.1109/ACCESS.2025.3555302",
        "volume": "13",
        "year": "2025"
    },
    "Shah2018": {
        "abstract": "Uneven illumination and shadows in document images cause a challenge for digitization applications and automated workflows. In this work, we propose a new method to recover unshadowed document images from images with shadows/un-even illumination. We pose this problem as one of estimating the shading and reflectance components of the given original image. Our method first estimates the shading and uses it to compute the reflectance. The output reflectance map is then used to improve the shading and the process is repeated in an iterative manner. The iterative procedure allows for a gradual compensation and allows our algorithm to even handle difficult hard shadows without introducing any artifacts. Experiments over two different datasets demonstrate the efficacy of our algorithm and the low computation complexity makes it suitable for most practical applications.",
        "author": "Shah, V. and Gandhi, V.",
        "booktitle": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "doi": "10.1109/ICASSP.2018.8462476",
        "issn": "2379-190X",
        "keywords": "type:Shadow Removal, Document Analysis",
        "pages": "1892-1896",
        "series": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "title": "An Iterative Approach for Shadow Removal in Document Images",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/ICASSP.2018.8462476",
        "year": "2018"
    },
    "Wang2020": {
        "abstract": "This paper proposes a simple yet effective method for removing shadows from text document images. Assuming that the document mainly contains texts, our method estimates the global and local background colors using statistical analysis of the whole image and local neighborhoods. By estimating the global and local background colors, we obtain the shadow map indicating the shadow ratio for each pixel. With the shadow map, a shadow-free image can be recovered by intrinsic decomposition. Experiments confirm that our method effectively removes the shadow of text document images regardless of the intensity, scope, and the number of shadows.",
        "author": "Wang, J.-R. and Chuang, Y.-Y.",
        "booktitle": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "doi": "10.1109/ICASSP40776.2020.9053378",
        "issn": "2379-190X",
        "keywords": "type: Document image shadow removal, document image processing",
        "pages": "1534-1538",
        "series": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "title": "Shadow Removal of Text Document Images by Estimating Local and Global Background Colors",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/ICASSP40776.2020.9053378",
        "year": "2020"
    },
    "Wang2025": {
        "abstract": "With the rapid development of document digitization, people have become accustomed to capturing and processing documents using electronic devices such as smartphones. However, the captured document images often suffer from issues like shadows and noise due to environmental factors, which can affect their readability. To improve the quality of captured document images, researchers have proposed a series of models or frameworks and applied them in distinct scenarios such as image enhancement, and document information extraction. In this paper, we primarily focus on shadow removal methods and open-source datasets. We concentrate on recent advancements in this area, first organizing and analyzing nine available datasets. Then, the methods are categorized into conventional methods and neural network-based methods. Conventional methods use manually designed features and include shadow map-based approaches and illumination-based approaches. Neural network-based methods automatically generate features from data and are divided into single-stage approaches and multi-stage approaches. We detail representative algorithms and briefly describe some typical techniques. Finally, we analyze and discuss experimental results, identifying the limitations of datasets and methods. Future research directions are discussed, and nine suggestions for shadow removal from document images are proposed. To our knowledge, this is the first survey of shadow removal methods and related datasets from document images.",
        "author": "Wang, Bingshu and Li, Changping and Zou, Wenbin and Zhang, Yongjun and Chen, Xuhang and Chen, C.L.\u00a0Philip",
        "day": "06",
        "doi": "10.1007/s44336-024-00010-9",
        "issn": "3005-060X",
        "journal": "Vicinagearth",
        "keywords": "type:Artificial intelligence, Document image, Shadow removal, Neural networks",
        "month": "Jan",
        "number": "1",
        "pages": "1",
        "title": "A comprehensive survey on shadow removal from document images: datasets, methods, and opportunities",
        "type": "Article",
        "url": "https://doi.org/10.1007/s44336-024-00010-9",
        "volume": "2",
        "year": "2025"
    },
    "Wang2025 ": {
        "abstract": "Shadows in document images are undesirable yet inevitable. They can decrease the clarity and readability of the images. The existing methods for removing shadows from documents still face some challenges, such as the traditional heuristics lack universality and the optimization goal of subnetworks is not consistent for multistage deep learning methods. In this paper, we introduce an end-to-end direct document shadow removal network (DDSR-Net), where we employ a 3-layer UNet++ as the backbone to extract features from diverse scales. To further improve the performance of DDSR-Net, we integrate the multi-scale attention (MSA) blocks into each node. The MSA block allocates different weights to feature vectors at different positions, achieving automatic feature alignment and significantly enhancing the end-to-end network's ability to handle shadow processing. To verify the effectiveness of the proposed DDSR-Net, qualitative and quantitative experiments are conducted on multiple open-source document shadow removal datasets. The experimental results demonstrate that our method outperforms the existing state-of-the-art methods on these datasets. Our code and models will be released to the public.",
        "author": "Wang, Bingshu and Wang, Ze and Liu, Wenjie and Huang, Xiaoshui and Chen, C. L. Philip and Zhao, Yue",
        "day": "21",
        "doi": "10.1007/s11633-024-1522-4",
        "issn": "2731-5398",
        "journal": "Machine Intelligence Research",
        "month": "Mar",
        "title": "DDSR-Net: Direct Document Shadow Removal Leveraging Multi-scale Attention",
        "type": "Article",
        "url": "https://doi.org/10.1007/s11633-024-1522-4",
        "year": "2025"
    },
    "Zhang2023": {
        "abstract": "Existing works on document image shadow removal mostly depend on learning and leveraging a constant background (the color of the paper) from the image. However, the constant background is less representative and frequently ignores other background colors, such as the printed colors, resulting in distorted results. In this paper, we present a color-aware background extraction network (CBENet) for extracting a spatially varying background image that accurately depicts the background colors of the document. Furthermore, we propose a background-guided document images shadow removal network (BGShadowNet) using the predicted spatially varying background as auxiliary information, which consists of two stages. At Stage I, a background-constrained decoder is designed to promote a coarse result. Then, the coarse result is refined with a background-based attention module (BAModule) to maintain a consistent appearance and a detail improvement module (DEModule) to enhance the texture details at Stage II. Experiments on two benchmark datasets qualitatively and quantitatively validate the superiority of the proposed approach over state-of-the-arts.",
        "author": "Zhang, L. and He, Y. and Zhang, Q. and Liu, Z. and Zhang, X. and Xiao, C.",
        "booktitle": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "doi": "10.1109/CVPR52729.2023.00181",
        "issn": "2575-7075",
        "keywords": "type: Computational imaging",
        "pages": "1818-1827",
        "series": "2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "title": "Document Image Shadow Removal Guided by Color-Aware Background",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/CVPR52729.2023.00181",
        "year": "2023"
    },
    "Zhou2024": {
        "abstract": "Shadows in scanned documents pose significant challenges for document analysis and recognition tasks due to their negative impact on visual quality and readability. Current shadow removal techniques, including traditional methods and deep learning approaches, face limitations in handling varying shadow intensities and preserving document details. To address these issues, we propose DocDeshadower, a novel multi-frequency Transformer-based model built upon the Laplacian Pyramid. By decomposing the shadow image into multiple frequency bands and employing two critical modules: the Attention-Aggregation Network for low-frequency shadow removal and the Gated Multi-scale Fusion Transformer for global refinement. DocDeshadower effectively removes shadows at different scales while preserving document content. Extensive experiments demonstrate DocDe-shadower's superior performance compared to state-of-the-art methods, highlighting its potential to significantly improve document shadow removal techniques. The code is available at https://github.com/leiyingtie/DocDeshadower.",
        "author": "Zhou, Z. and Lei, Y. and Chen, X. and Luo, S. and Zhang, W. and Pun, C.-M. and Wang, Z.",
        "booktitle": "2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
        "doi": "10.1109/SMC54092.2024.10831480",
        "keywords": "type:Deep learning, Visualization, Text analysis, Laplace equations, Codes, Image color analysis, Face recognition, Logic gates, Transformers, Cybernetics",
        "pages": "2468-2473",
        "series": "2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
        "title": "DocDeshadower: Frequency-Aware Transformer for Document Shadow Removal",
        "type": "InProceedings",
        "url": "https://doi.org/10.1109/SMC54092.2024.10831480",
        "year": "2024"
    }
}});